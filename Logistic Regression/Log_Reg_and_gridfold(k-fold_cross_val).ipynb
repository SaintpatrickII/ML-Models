{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression is the bread & butter for dealing with classification problems\n",
    "# it is a supervised learning algorithm where fearures are discrete binary variables & is extremely useful when dealing with types of features\n",
    "#  whereas linear regression is a linear model that is used to predict continuous values here we encode the features as binary variables\n",
    "# and then use logistic regression to predict the class\n",
    "# logistic regression is great for clean data, but as data becomes more convuluted, logistic regression becomes less accurate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "logreg = LogisticRegression()\n",
    "print(logreg.get_params())\n",
    "# here we can see all the hyperparameters avalinble for logistic regression, note this c value here\n",
    "# is the regularization parameter, which is the penalty for the model to avoid overfitting\n",
    "# regualarization is just simply haw close the model will fit to the training data\n",
    "# however c isnt actually a regularization parameter, c = 1/lambda where lambda is the regularization parameter\n",
    "# the higher our c value, the more regularization is applied, the more the model is penalised, it is more complex & more likely to overfit\n",
    "# exact opposite happens at low c, the modelis more basic & easier to underfit as it has a higher regularisation parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_check_feature_names', '_check_n_features', '_estimator_type', '_get_param_names', '_get_tags', '_more_tags', '_predict_proba_lr', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_validate_data', 'class_weight', 'decision_function', 'densify', 'dual', 'fit', 'fit_intercept', 'get_params', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'predict', 'predict_log_proba', 'predict_proba', 'random_state', 'score', 'set_params', 'solver', 'sparsify', 'tol', 'verbose', 'warm_start']\n"
     ]
    }
   ],
   "source": [
    "# what about the methods & attributes??\n",
    "print(dir(logreg))\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>912bb259-3ad9-457b-9db1-ce1da9016057</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b166d305-b852-4bdd-83f4-465b20da94fa</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68f5a29d-0075-4d60-81c1-ab684a82e50c</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f6a309d7-d247-446a-9b5e-aceefdd4334d</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2c2b3a6f-15b3-4289-937a-15482d9f5781</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12599</th>\n",
       "      <td>cdec1c5c-c4b1-42db-afbe-3fa68ea4b87d</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12600</th>\n",
       "      <td>dc99e40f-6b15-494d-9fb7-f0d02e9781f9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12601</th>\n",
       "      <td>c8488028-bf07-4258-a4c2-56d2fe387835</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12602</th>\n",
       "      <td>c6113145-89c8-47cd-9211-38f29d016cc7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12603</th>\n",
       "      <td>ed2aaf88-616c-4e6b-af49-bbdf7c0fbd06</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10188 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   image_id  category\n",
       "0      912bb259-3ad9-457b-9db1-ce1da9016057         6\n",
       "1      b166d305-b852-4bdd-83f4-465b20da94fa         6\n",
       "2      68f5a29d-0075-4d60-81c1-ab684a82e50c         6\n",
       "3      f6a309d7-d247-446a-9b5e-aceefdd4334d         6\n",
       "4      2c2b3a6f-15b3-4289-937a-15482d9f5781         6\n",
       "...                                     ...       ...\n",
       "12599  cdec1c5c-c4b1-42db-afbe-3fa68ea4b87d        12\n",
       "12600  dc99e40f-6b15-494d-9fb7-f0d02e9781f9        12\n",
       "12601  c8488028-bf07-4258-a4c2-56d2fe387835        12\n",
       "12602  c6113145-89c8-47cd-9211-38f29d016cc7        12\n",
       "12603  ed2aaf88-616c-4e6b-af49-bbdf7c0fbd06        12\n",
       "\n",
       "[10188 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = '/Users/paddy/Desktop/AiCore/facebook_ml/final_dataset/image_data.json'\n",
    "\n",
    "data = pd.read_json(data)\n",
    "data\n",
    "# in this dataset if is for multiclass classification, so we need to encode the features as values for all the categories, in my dataset there were 13 categories so each category has a number assiciated 0-12,\n",
    "# this can be done using sklean's LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# say we had a dataset with multiple columns of features and a column of labels, if either of this datasets is a pandas series, we have to include an extra 'header' argurement,\n",
    "# this header arguement means that pandas will not use the first row of the dataframe as the column names\n",
    "\n",
    "features_file = 'filepath/to/features'\n",
    "labels_file = 'filepath/to/labels'\n",
    "features = pd.read_json(features_file)\n",
    "labels = pd.read_json(labels_file, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "\n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}'.format(round(mean, 3), round(std * 2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "parameters = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(lr, parameters, cv=5)\n",
    "cv.fit(features, labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e510884cfc2d161432d212cfd768f3de9a805e4599418f66cff32f16447a06c3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
